{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of AI in Financial Services\n",
    "\n",
    "Deep learning is one of the most exciting new technologies being used in the financial services industry, and when used correctly, can improve investment returns. While tasks such as computer vision and natural language processing (NLP) are well-researched areas, the use of Artificial Intelligence (AI) techniques in financial services is still growing. It's important to note that some of the most advanced, lucrative deep learning techniques in AI are not published, nor will they ever be. The lucrative nature of the financial services space necessitates guarding advanced algorithms and measures, and so in this chapter we will focus on principles. \n",
    "\n",
    "The application of AI in the financial services industry is nuanced; it's being used in areas where it can perform faster and better than a human could, but still isn't being used ubiquitously. By far, the most ubiquitous use of deep learning in the financial services industry is in feature engineering.\n",
    "\n",
    "An entire book could be written simply on the topic of deep learning in financial services. While we won't go into depth on financial topics, we will touch upon the definitions of terms and concepts that we introduce throughout this chapter. We'll be covering several basic AI-driven trading methods, as well as an event-based trading method that utilizes a new type of Artificial Neural Network (ANN) that we have yet to talk aboutâ€”the Neural Tensor Network. Lastly, we'll look at how deep learning can aid us in developing optimal portfolios of stocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Trading Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapation from the Personae Platform by @Ceruleanacg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from time import time\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a class to manage the trading position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingPosition(object):\n",
    "   ''' Class that manages the trading position of our platform utilizing the Personae platform'''\n",
    "    \n",
    "    def __init__(self, action, buy_price, amount, next_price):\n",
    "        self.action = action ## Status code for what action our algorithm is taking\n",
    "        self.amount = amount ## The amount of the trade\n",
    "        self.buy_price = buy_price ## The purchase price of a trade\n",
    "        self.current_price = buy_price ## Buy price of the trade\n",
    "        self.current_value = self.current_price * self.amount\n",
    "        self.pro_value = next_price * self.amount \n",
    "        \n",
    "    def TradeStatus(self, current_price, next_price, amount):\n",
    "        ''' Manages the status of a trade that is in action '''\n",
    "        self.current_price = current_price ## updates the current price variable that is maintained within the class\n",
    "        self.current_value = self.current_price * amount\n",
    "        pro_value = next_price * amount\n",
    "\n",
    "    def BuyStock(self, buy_price, amount, next_price):\n",
    "        ''' Function to buy a stock '''\n",
    "        self.buy_price = ((self.amount * self.buy_price) + (amount * buy_price)) / (self.amount + amount)\n",
    "        self.amount += amount\n",
    "        self.TradeStatus(buy_price, next_price)\n",
    "\n",
    "    def SellStock(self, sell_price, amount, next_price):\n",
    "        ''' Function to sell a stock '''\n",
    "         self.current_price = sell_price\n",
    "         self.amount -= amount\n",
    "         self.TradeStatus(sell_price, next_price)\n",
    "            \n",
    "    def HoldStock(self, current_price, next_price):\n",
    "        ''' Function to hold a stock '''\n",
    "        self.TradeStatus(current_price, next_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an artificial trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trader(object):\n",
    " ''' An Artificial Trading Agent. From the Personae Platform'''\n",
    "\n",
    "    def __init__(self, market, cash=100000000.0):\n",
    "         ## Initialize all the variables we need for our trader\n",
    "         self.cash = cash ## Our Cash Variable\n",
    "         self.market = market ## current market values\n",
    "         self.codes = market.codes ## buy, sell, or hold\n",
    "         self.positions = [] ## current position held\n",
    "         self.action_times = 0\n",
    "         self.initial_cash = cash ## the initial cash value in the account\n",
    "         self.max_cash = cash * 3\n",
    "         self.total_rewards = 0\n",
    "         self.cur_action_code = None\n",
    "         self.cur_action_status = None\n",
    "         self.episode_time = 0\n",
    "         self.history_profits = []\n",
    "         self.history_baselines = []\n",
    "         self.action_dic = {ActionCode.Buy: self.buy, ActionCode.Hold: self.hold, ActionCode.Sell: self.sell}\n",
    "        \n",
    "    ## CountCode will keep track of how many action codes to handle\n",
    "    @property\n",
    "    def CountCodes(self):\n",
    "        return len(self.codes)\n",
    "\n",
    "    @property\n",
    "    def ActionSpace(self):\n",
    "        return self.CountCodes * 3\n",
    " \n",
    "    ## Define what our total profits are\n",
    "    @property\n",
    "    def TotalProfits(self):\n",
    "        return self.cash + self.holdings_value - self.initial_cash\n",
    "\n",
    "    ## Define the total value of all currently held assets\n",
    "    @property\n",
    "    def HoldingsValue(self):\n",
    "        holdings_value = 0\n",
    "        for position in self.positions:\n",
    "            ## Define holdings value as the total value of all current positions\n",
    "            holdings_value += position.current_value\n",
    "            return holdings_value\n",
    "\n",
    "    def BuyAction(self, action, stock, amount, stock_next):\n",
    "        ## Check if there is enough cash in the account\n",
    "        amount = amount if self.cash > stock.close * amount else int(math.floor(self.cash / stock.close))\n",
    "        if amount > 0:\n",
    "            ## Check if we already hold a certain security\n",
    "            if not self._exist_position(action):\n",
    "                ## If we do not own the security, feed the information needed to purchase it to our TradingPosition Class\n",
    "                position = TradingPosition(action, stock.close, amount, stock_next.close)\n",
    "                self.positions.append(position) ## Add the new security to our list of securities owned\n",
    "            else:\n",
    "                # Get position and update if possible.\n",
    "                position = self._position(action)\n",
    "                position.BuyStock(stock.close, amount, stock_next.close)\n",
    "                \n",
    "            ## Udate our current cash on hand\n",
    "            self.cash -= amount * stock.close\n",
    "            self._update_reward(ActionCode.Buy, ActionStatus.Success, position)\n",
    "            \n",
    "            else:\n",
    "                 self.market.logger.info(\"Code: {}, insufficient cash reserves.\".format(code))\n",
    "        if self._exist_position(code):\n",
    "            position = self._position(code)\n",
    "            position.update_status(stock.close, stock_next.close)\n",
    "            self._update_reward(ActionCode.Buy, ActionStatus.Failed, position)\n",
    "        \n",
    "    def SellAction(self, code, stock, amount, stock_next):\n",
    "            ## First, check to see if we own the secutity in questions, if not, return an error\n",
    "            if not self._exist_position(code):\n",
    "                self.market.logger.info(\"Code: {}, does not exits in your account\".format(code))\n",
    "                return self._update_reward(ActionCode.Sell, ActionStatus.Failed, None)           \n",
    "            \n",
    "            ## Otherwise, attempt to sell the stock \n",
    "            position = self._position(code)\n",
    "            amount = amount if amount < position.amount else position.amount\n",
    "            position.sub(stock.close, amount, stock_next.close)\n",
    " \n",
    "            ## Lastly, update the amount of cash we now have on hand\n",
    "            self.cash += amount * stock.close\n",
    "            self._update_reward(ActionCode.Sell, ActionStatus.Success, position)\n",
    "    \n",
    "        def HoldAction(self, code, stock, _, stock_next):\n",
    "            if not self._exist_position(code):\n",
    "                self.market.logger.info(\"Code: {}, you do not own this stock\".format(code))\n",
    "                return self._update_reward(ActionCode.Hold,         ActionStatus.Failed, None)\n",
    "     \n",
    "            position = self._position(code)\n",
    "            position.update_status(stock.close, stock_next.close)\n",
    "            self._update_reward(ActionCode.Hold, ActionStatus.Success, position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for handling the trader's interaction with market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MarketHandler(object):\n",
    "    ''' Class for handling our platform's interaction with market data. From the Personae Platform'''\n",
    "    Running = 0\n",
    "    Done = -1\n",
    "\n",
    "    def __init__(self, codes, start_date=\"2008-01-01\", end_date=\"2018-05-31\", **options):\n",
    "         self.codes = codes\n",
    "         self.index_codes = []\n",
    "         self.state_codes = []\n",
    "         self.dates = []\n",
    "         self.t_dates = []\n",
    "         self.e_dates = []\n",
    "         self.origin_frames = dict()\n",
    "         self.scaled_frames = dict()\n",
    "         self.data_x = None\n",
    "         self.data_y = None\n",
    "         self.seq_data_x = None\n",
    "         self.seq_data_y = None\n",
    "         self.next_date = None\n",
    "         self.iter_dates = None\n",
    "         self.current_date = None\n",
    "\n",
    "         ## Initialize the stock data that will be fed in \n",
    "         self._init_data(start_date, end_date)\n",
    "\n",
    "         self.state_codes = self.codes + self.index_codes\n",
    "         self.scaler = [scaler() for _ in self.state_codes]\n",
    "         self.trader = Trader(self, cash=self.init_cash)\n",
    "         self.doc_class = Stock if self.m_type == 'stock' else Future\n",
    "            \n",
    "    def _init_data_frames(self, start_date, end_date):\n",
    "        self._validate_codes()\n",
    "        columns, dates_set = ['open', 'high', 'low', 'close', 'volume'], set()\n",
    "        ## Load the actual data\n",
    "        for index, code in enumerate(self.state_codes):\n",
    "            instrument_docs = self.doc_class.get_k_data(code, start_date, end_date)\n",
    "            instrument_dicts = [instrument.to_dic() for instrument in instrument_docs]\n",
    "            dates = [instrument[1] for instrument in instrument_dicts]\n",
    "            instruments = [instrument[2:] for instrument in instrument_dicts]\n",
    "            dates_set = dates_set.union(dates)\n",
    "            scaler = self.scaler[index]\n",
    "            scaler.fit(instruments)\n",
    "            instruments_scaled = scaler.transform(instruments)\n",
    "            origin_frame = pd.DataFrame(data=instruments, index=dates, columns=columns)\n",
    "            scaled_frame = pd.DataFrame(data=instruments_scaled, index=dates, columns=columns)\n",
    "            self.origin_frames[code] = origin_frame\n",
    "            self.scaled_frames[code] = scaled_frame\n",
    "            self.dates = sorted(list(dates_set))\n",
    "        for code in self.state_codes:\n",
    "            origin_frame = self.origin_frames[code]\n",
    "            scaled_frame = self.scaled_frames[code]\n",
    "            self.origin_frames[code] = origin_frame.reindex(self.dates, method='bfill')\n",
    "            self.scaled_frames[code] = scaled_frame.reindex(self.dates, method='bfill')\n",
    "        \n",
    "    def _init_env_data(self):\n",
    "        if not self.use_sequence:\n",
    "            self._init_series_data()\n",
    "        else:\n",
    "            self._init_sequence_data()\n",
    "            self._init_data_frames(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Price Prediction Utilizing LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapation from the Personae Platform by @Ceruleanacg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TradingRNN():\n",
    "     ''' An RNN Model for Derivatives Training '''\n",
    "    def __init__(self, session, env, seq_length, x_space, y_space, **options):\n",
    "        self.seq_length, self.x_space, self.y_space = seq_length, x_space, y_space\n",
    "\n",
    "    try:\n",
    "        self.hidden_size = options['hidden_size']\n",
    "    except KeyError:\n",
    "         self.hidden_size = 1\n",
    "            \n",
    "    self.x = tf.placeholder(tf.float32, [None, self.seq_length, self.x_space])\n",
    "    self.label = tf.placeholder(tf.float32, [None, self.y_space])\n",
    "        \n",
    "    with tf.variable_scope('network_body'):\n",
    "        self.rnn = self.add_rnn(1, self.hidden_size)\n",
    "        self.rnn_output, _ = tf.nn.dynamic_rnn(self.rnn, self.x, dtype=tf.float32)\n",
    "        self.rnn_output = self.rnn_output[:, -1]\n",
    "        self.rnn_output_dense = self.add_fc(self.rnn_output, 16)\n",
    "        self.y = self.add_fc(self.rnn_output_dense, self.y_space)\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('loss'):\n",
    "        self.loss = tf.losses.mean_squared_error(self.y, self.label)\n",
    "    with tf.variable_scope('train'):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        for step in range(self.train_steps):\n",
    "            batch_x, batch_y = self.env.get_batch_data(self.batch_size)\n",
    "            _, loss = self.session.run([self.train_op, self.loss],             feed_dict={self.x: batch_x, self.label: batch_y})\n",
    "        if (step + 1) % 1000 == 0:\n",
    "            logging.warning(\"Step: {0} | Loss: {1:.7f}\".format(step + 1, loss))\n",
    "        if step > 0 and (step + 1) % self.save_step == 0:\n",
    "             if self.enable_saver:\n",
    "                 self.save(step)\n",
    "            \n",
    "    def predict(self, x):\n",
    "         return self.session.run(self.y, feed_dict={self.x: x})\n",
    "\n",
    "    def main(args):\n",
    "        mode = 'test'\n",
    "        codes = [\"600036\", \"601998\"]\n",
    "        market = args.market\n",
    "        train_steps = 20000\n",
    "        training_data_ratio = 0.98\n",
    "\n",
    "        env = Market(codes, start_date=\"2008-01-01\", end_date=\"2018-01-01\", **{\n",
    "            \"market\": market,\n",
    "            \"use_sequence\": True,\n",
    "            \"scaler\": MinMaxScaler,\n",
    "            \"mix_index_state\": True,\n",
    "            \"training_data_ratio\": training_data_ratio,\n",
    "        })\n",
    "\n",
    "        model_name = os.path.basename(__file__).split('.')[0]\n",
    "\n",
    "        RNN = TradingRNN(tf.Session(config=config), env, env.seq_length, env.data_dim, env.code_count, **{\n",
    "            \"mode\": mode,\n",
    "            \"hidden_size\": 5,\n",
    "            \"enable_saver\": True,\n",
    "            \"train_steps\": train_steps,\n",
    "            \"enable_summary_writer\": True,\n",
    "            \"save_path\": os.path.join(CHECKPOINTS_DIR, \"SL\",         model_name, market, \"model\"),\n",
    "            \"summary_path\": os.path.join(CHECKPOINTS_DIR, \"SL\", model_name, market, \"summary\"),\n",
    "         })\n",
    "\n",
    "        RNN.run()\n",
    "        RNN.eval_and_plot()\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "         main(model_launcher_parser.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning in Asset Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder in this example is adapted from that by time series autoencoder by @/RobRomijnders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf from tensorflow.contrib.rnn import LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse the Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibb = defaultdict(defaultdict)\n",
    "ibb_full = pd.read_csv('data/ibb.csv', index_col=0).astype('float32')\n",
    "\n",
    "ibb_lp = ibb_full.iloc[:,0] \n",
    "ibb['calibrate']['lp'] = ibb_lp[0:104]\n",
    "ibb['validate']['lp'] = ibb_lp[104:]\n",
    "\n",
    "ibb_net = ibb_full.iloc[:,1] \n",
    "ibb['calibrate']['net'] = ibb_net[0:104]\n",
    "ibb['validate']['net'] = ibb_net[104:]\n",
    "\n",
    "ibb_percentage = ibb_full.iloc[:,2] \n",
    "ibb['calibrate']['percentage'] = ibb_percentage[0:104]\n",
    "ibb['validate']['percentage'] = ibb_percentage[104:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop an Autoencoder to Encode the Market Data\n",
    "Adapted from @RobRomijnders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MarketEncoder():\n",
    "    ''' AutoEncoder for Data Drive Portfolio Allocation '''\n",
    "    def __init__(self):\n",
    "        ## Hyperparameters frot the market encoder\n",
    "        self.layers = tf.placeholder('int') ## Number of layers\n",
    "        self.hl = tf.placeholder('int') ## Size of the hidden layers\n",
    "        self.maximum_gradient = tf.placeholder('int') ## The Maximum Gradient\n",
    "        self.batch = tf.placeholder('int')\n",
    "        self.crd = tf.placeholder('int') \n",
    "        self.num_l = tf.placeholder('int')\n",
    "        self.lr = tf.placeholder('float') ## Learning Rate\n",
    "        self.batch_size = batch_size \n",
    "        \n",
    "        ## sl will represent the length of an input sequence, which we would like to eb dynamic based on the data \n",
    "        sl = tf.placeholder(\"int\")\n",
    "        self.sl = sl\n",
    "        \n",
    "        ## X will be a placeholder to represent our input data\n",
    "        self.x = tf.placeholder(\"float\", shape=[batch_size, self.sl], name='input')\n",
    "        self.x_exp = tf.expand_dims(self.x, 1)\n",
    "        self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "    ## Layer to Generate the Initial Hidden State from the Encoder\n",
    "    with tf.name_scope(\"Initial_State\") as scope:\n",
    "        ## Weights Parameter State\n",
    "        weights_state = tf.get_variable([num_l, hidden_size])\n",
    "\n",
    "        ## Bias Paramter State\n",
    "        bias_state = tf.get_variable('b_state', [hidden_size])\n",
    " \n",
    "        ## Hidden State\n",
    "        hidden_state= tf.nn.xw_plus_b(self.z_mu, W_state, b_state, name='hidden_state')\n",
    "\n",
    "    ## Create the Encoder \n",
    "    def encoder(self):\n",
    "        '''Encoder Operation for the autoencoder'''\n",
    "        \n",
    "        ## For the encoder, we will use an LSTM cell with Dropout\n",
    "        EncoderCell = tf.contrib.rnn.MultiRNNCell([LSTMCell(self.hl) for _ in range(layers)])\n",
    "        EncoderCell = tf.contrib.rnn.DropoutWrapper(EncoderCell, output_keep_prob=self.keep_prob)\n",
    "\n",
    "        ## Set the initial hidden state of the encoder\n",
    "        EncInitialState = EncoderCell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        ## Weights Factor\n",
    "        weights = tf.get_variable('weights', [self.hl, num_l])\n",
    "\n",
    "        ## Outputs of the Encoder Layer\n",
    "        outputs_enc, _ = tf.contrib.rnn.static_rnn(cell_enc, inputs=tf.unstack(self.x_exp, axis=2),\n",
    "        initial_state=initial_state_enc)\n",
    "        cell_output = outputs_enc[-1]\n",
    "\n",
    "        ## Bias Factor\n",
    "        biases = tf.get_variable('biases', [num_l])\n",
    " \n",
    "        ## Mean of the latent space variables\n",
    "        z = tf.nn.xw_plus_b(cell_output, weights, biases) \n",
    "\n",
    "        lat_mean, lat_var = tf.nn.moments(self.z_mu, axes=[1])\n",
    "        self.loss_lat_batch = tf.reduce_mean(tf.square(lat_mean) + lat_var - tf.log(lat_var) - 1)\n",
    "        \n",
    "    ## Decoder Layer \n",
    "    def decoder(self):  \n",
    "        ''' Decoder operations for the AE'''\n",
    " \n",
    "        ## Create a base decoder cell\n",
    "        DecoderCell = tf.contrib.rnn.MultiRNNCell([LSTMCell(self.hl) for _ in range(self.layers)])\n",
    "\n",
    "        ## Set an initial state for the decoder layer\n",
    "        DecState = tuple([(hidden_state, hidden_state)] * self.layers)\n",
    "        decIn = [tf.zeros([batch_size, 1])] * self.sl\n",
    " \n",
    "        ## Run the decoder layer\n",
    "        outputs_dec, _ = tf.contrib.rnn.static_rnn(cell_dec, inputs=dec_inputs, initial_state=DecState)     \n",
    "            \n",
    "    def output_layer(self):\n",
    "        '''A dense layer that acts as the output layer of the encoder'''\n",
    "        \n",
    "        params_o = 2 * crd \n",
    "        W_o = tf.get_variable('W_o', [hidden_size, params_o])\n",
    "        b_o = tf.get_variable('b_o', [params_o])\n",
    "        outputs = tf.concat(outputs_dec, axis=0) \n",
    "        h_out = tf.nn.xw_plus_b(outputs, W_o, b_o)\n",
    "        h_mu, h_sigma_log = tf.unstack(tf.reshape(h_out, [sl, batch_size, params_o]), axis=2)\n",
    "        h_sigma = tf.exp(h_sigma_log)\n",
    "        dist = tf.contrib.distributions.Normal(h_mu, h_sigma)\n",
    "        px = dist.log_prob(tf.transpose(self.x))\n",
    "        loss_seq = -px\n",
    "        self.loss_seq = tf.reduce_mean(loss_seq)\n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        '''Training Function'''\n",
    " \n",
    "        ## Global Step Function for Training\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    " \n",
    "        ## Exponential Decay for the learning rate. Takes the initial LR and decays over time\n",
    "        lr_delta = tf.train.exponential_decay(self.lr, global_step, 1000, 0.1, staircase=False)\n",
    "\n",
    "        ## Loss Function for the Network\n",
    "        self.loss = self.loss_seq + self.loss_lat_batch\n",
    " \n",
    "        ## Utilize gradient clipping to prevent exploding gradients\n",
    "        grads = tf.gradients(self.loss, tvars)\n",
    "        grads, _ = tf.clip_by_global_norm(grads, self.maximum_gradient)\n",
    "        self.numel = tf.constant([[0]])\n",
    "\n",
    "        ## Lastly, apply the optimization process\n",
    "        optimizer = tf.train.AdamOptimizer(lr_delta)\n",
    "        gradients = zip(grads, tvars)\n",
    "        self.train_step = optimizer.apply_gradients(gradients, global_step=global_step)\n",
    "        self.numel = tf.constant([[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the autoencoder on the market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "label = [] # The label to save to visualize the latent space\n",
    "z_run = []\n",
    "\n",
    "while start + batch_size < Nval:\n",
    "    run_ind = range(start, start + batch_size)\n",
    "    z_mu_fetch = sess.run(model.z_mu, feed_dict={model.x: X_val[run_ind], model.keep_prob: 1.0})\n",
    "    z_run.append(z_mu_fetch)\n",
    "    start += batch_size\n",
    "\n",
    "z_run = np.concatenate(z_run, axis=0)\n",
    "label = y_val[:start]\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), step)\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = model.z_mu.name\n",
    "\n",
    "communal_information = []\n",
    "\n",
    "for i in range(0,83):\n",
    "    diff = np.linalg.norm((data.iloc[:,i] - reconstruct[:,i])) # 2 norm difference\n",
    "    communal_information.append(float(diff))\n",
    " \n",
    "print(\"stock #, 2-norm, stock name\")\n",
    "ranking = np.array(communal_information).argsort()\n",
    "for stock_index in ranking:\n",
    "    print(stock_index, communal_information[stock_index], stock['calibrate']['net'].iloc[:,stock_index].name)\n",
    "\n",
    "    if True:\n",
    "        sess.run(model.init_op)\n",
    "        writer = tf.summary.FileWriter(LOG_DIR, sess.graph) # writer for Tensorboard\n",
    "\n",
    "        step = 0 # Step is a counter for filling the numpy array perf_collect\n",
    "    for i in range(max_iterations):\n",
    "        batch_ind = np.random.choice(N, batch_size, replace=False)\n",
    "        result = sess.run([model.loss, model.loss_seq, model.loss_lat_batch, model.train_step],\n",
    "        feed_dict={model.x: X_train[batch_ind], model.keep_prob: dropout})\n",
    "\n",
    "    if i % plot_every == 0:\n",
    "        perf_collect[0, step] = loss_train = result[0]\n",
    "        loss_train_seq, lost_train_lat = result[1], result[2]\n",
    "\n",
    "    batch_ind_val = np.random.choice(Nval, batch_size, replace=False)\n",
    "\n",
    "    result = sess.run([model.loss, model.loss_seq, model.loss_lat_batch, model.merged],\n",
    "    feed_dict={model.x: X_val[batch_ind_val], model.keep_prob: 1.0})\n",
    "    perf_collect[1, step] = loss_val = result[0]\n",
    "    loss_val_seq, lost_val_lat = result[1], result[2]\n",
    "    summary_str = result[3]\n",
    "    writer.add_summary(summary_str, i)\n",
    "    writer.flush()\n",
    "\n",
    "    print(\"At %6s / %6s train (%5.3f, %5.3f, %5.3f), val (%5.3f, %5.3f,%5.3f) in order (total, seq, lat)\" % (\n",
    " i, max_iterations, loss_train, loss_train_seq, lost_train_lat, loss_val, loss_val_seq, lost_val_lat))\n",
    " step += 1\n",
    "if False:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Reconconstruct the Index Utilizing the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which_stock = 1\n",
    "\n",
    "stock_autoencoder = copy.deepcopy(reconstruct[:, which_stock])\n",
    "stock_autoencoder[0] = 0\n",
    "stock_autoencoder = stock_autoencoder.cumsum()\n",
    "stock_autoencoder += (stock['calibrate']['lp'].iloc[0, which_stock])\n",
    "\n",
    "pd.Series(stock['calibrate']['lp'].iloc[:, which_stock].as_matrix(), index=pd.date_range(start='01/06/2012', periods=104, freq='W')).plot(label='stock original', legend=True)\n",
    "pd.Series(stock_autoencoder, index=pd.date_range(start='01/06/2012', periods = 104,freq='W')).plot(label='stock autoencoded', legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

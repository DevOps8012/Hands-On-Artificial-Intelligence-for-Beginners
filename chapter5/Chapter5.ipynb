{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs), or ConvNets, are a special class of feedforward networks; they are primarily used for computer vision tasks, but have also been adapted to other domains with unstructured data, such as natural language processing. As they are feedforward networks, they are very similar to the simple networks that we just learned about; information passes through them in one direction, and they are made up of layers, weights, and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogs_dir = '/users/patricksmith/desktop/Chp5/dataset/training/dogs/'\n",
    "cats_dir = '/users/patricksmith/desktop/Chp5/dataset/training/cats/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images = [dogs_dir + i for i in os.listdir(dogs_dir) if 'dog' in i]\n",
    "cat_images = [cats_dir + i for i in os.listdir(cats_dir) if 'cat' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process the images\n",
    "This preprocessing code for the images is from @jshin49 on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img, img_size, pixel_depth):\n",
    "    img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    if (img.shape[0] >= img.shape[1]): \n",
    "        resizeto = (img_size, int(\n",
    "            round(img_size * (float(img.shape[1]) / img.shape[0]))))\n",
    "    else:\n",
    "        resizeto = (\n",
    "            int(round(img_size * (float(img.shape[0]) / img.shape[1]))), img_size)\n",
    "\n",
    "    img = cv2.resize(img, (resizeto[1], resizeto[\n",
    "        0]), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img, 0, img_size - img.shape[0], 0, img_size - img.shape[1], cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "    img = normalize_image(img, pixel_depth)\n",
    "\n",
    "    return img[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(image, pixel_depth):\n",
    "    image_data = np.array(image, dtype=np.float32)\n",
    "    image_data[:, :, 0] = (image_data[:, :, 0].astype(\n",
    "        float) - pixel_depth / 2) / pixel_depth\n",
    "    image_data[:, :, 1] = (image_data[:, :, 1].astype(\n",
    "        float) - pixel_depth / 2) / pixel_depth\n",
    "    image_data[:, :, 2] = (image_data[:, :, 2].astype(\n",
    "        float) - pixel_depth / 2) / pixel_depth\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = 255.0\n",
    "image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dogs = []\n",
    "training_cats = []\n",
    "\n",
    "for dog in dog_images:\n",
    "    p_image = process_image(dog, image_size, depth)\n",
    "    training_dogs.append([np.array(p_image), 1])\n",
    "\n",
    "for cat in cat_images:\n",
    "    p_image = process_image(cat, image_size, depth)\n",
    "    training_cats.append([np.array(p_image), 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split and define the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_data = np.array(np.array_split(train_dogs, 12500 / (batch_size / 2)))\n",
    "cat_data = np.array(np.array_split(train_cats, 12500 / (batch_size / 2))\n",
    "\n",
    "total_batch = []\n",
    "for dog_image, cat_image in zip(dog_data, cat_data):\n",
    "    batch = np.concatenate([dog_image, cat_image])\n",
    "    total_batch.append(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = int(len(total_batch) * 0.1)\n",
    "validation_set = total_batch[-validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_batches = total_batch[:-validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_batches = total_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_network(x, image_size, color_channels):\n",
    "\n",
    "    ## Input Layer\n",
    "    input_layer = tf.reshape(x, [-1, image_size, image_size, color_channels])\n",
    "\n",
    "    ## First convolutional layer with pooling\n",
    "    convolution_one = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[3, 3],\n",
    "            padding=\"same\", kernel_initializer=initializer, kernel_regularizer=regularizer,\n",
    "            use_bias=True, bias_initializer=initializer, bias_regularizer=regularizer,\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_one = tf.layers.max_pooling2d(inputs=convolution_one, pool_size=[2, 2], strides=(2, 2))\n",
    "    \n",
    "    ## Second convolutional layer with pooling\n",
    "    convolution_two = tf.layers.conv2d(inputs=pooling_one, filters=32, kernel_size=[3, 3],\n",
    "            padding=\"same\", kernel_initializer=initializer, kernel_regularizer=regularizer,\n",
    "            use_bias=True, bias_initializer=initializer, bias_regularizer=regularizer,\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_two = tf.layers.max_pooling2d(inputs=convolution_two, pool_size=[2, 2], strides=(2, 2))\n",
    "    \n",
    "    ## Third Convolutional layer with pooling\n",
    "    convolution_three = tf.layers.conv2d(inputs=pooling_two, filters=64, kernel_size=[3, 3],\n",
    "            padding=\"same\", kernel_initializer=initializer, kernel_regularizer=regularizer,\n",
    "            use_bias=True, bias_initializer=initializer, bias_regularizer=regularizer,\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pooling_three = tf.layers.max_pooling2d(inputs=convolution_three, pool_size=[2, 2], strides=(2, 2))\n",
    "    \n",
    "    ## Flatting layer\n",
    "    flatten_layer = tf.reshape(pooling_three, [-1, 8 * 8 * 64])\n",
    "    \n",
    "    ## Fully Connected Layer with dropout \n",
    "    fc_layer = tf.layers.dense(inputs=flatten_layer, units=1024, activation=tf.nn.relu,\n",
    "            kernel_initializer=initializer, kernel_regularizer=regularizer,\n",
    "            use_bias=True, bias_initializer=initializer, bias_regularizer=regularizer)\n",
    "    dropout_layer = tf.layers.dropout(inputs=fc_layer, rate=dropout_rate, training=True)\n",
    "    \n",
    "    ## Output Layer\n",
    "    output = tf.layers.dense(inputs=dropout_layer, units=1, activation=tf.nn.sigmoid) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[None, image_size, image_size, color_channels], dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None, 1], dtype=tf.float32, name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the training parameters\n",
    "-Image size represents the image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "training_epochs = 20\n",
    "batch_size = 32\n",
    "display = 1\n",
    "threshold = 0.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the network and optimizer before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "regularizer = tf.contrib.layers.l2_regularizer(0.001)\n",
    "\n",
    "##Construct the model\n",
    "model_output = convolutional_network(x)\n",
    "\n",
    "## Define the optimizer and the loss function for the network \n",
    "loss = tf.losses.log_loss(labels=y, predictions=model_output)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "#tf.train.RMSPropOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "## Define the accuracy metric\n",
    "thresholds = tf.fill([batch_size], threshold)\n",
    "predictions = tf.greater_equal(model_output, thresholds)\n",
    "correct_prediction = tf.equal(predictions, tf.cast(y, tf.bool))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start the training session\n",
    "with tf.Session() as sess:\n",
    "    ## Initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):           \n",
    "        for batch in training_batches:\n",
    "            batch_images, batch_labels = map(list, zip(*batch))\n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_labels = np.array(batch_labels).reshape(-1, 1)\n",
    "            \n",
    "            ## Run the training procedures\n",
    "            _, l, acc = sess.run([optimizer, loss, accuracy], feed_dict={x: batch_images, y: batch_labels})\n",
    "        \n",
    "        if epoch % display == 0:\n",
    "            print('\\nEpoch: %d, Loss: %f, Accuracy: %f' % (epoch + 1, l, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

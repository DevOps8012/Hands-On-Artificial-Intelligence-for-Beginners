{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative adevrsarial networks (GANs) are a class of networks that were introduced by Ian Goodfellow in 2014. In GANs, two neural networks play off against one another as adversaries in an actor-critic model, where one is the creator and the other the scrutinizer. The creator, referred to as the generator network, tries to create samples that will fool the scrutinizer, the discriminator network. These two increasingly play off against one another, with the generator network creating increasingly believable samples and the discriminator network getting increasingly good at spotting the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "training_data = (mnist.train.images - 0.5) / 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(x, initializer):\n",
    "    \n",
    "    layer_1 = tf.layers.dense(x, units=256, activation=tf.nn.relu, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='input_layer')\n",
    "    \n",
    "    layer_2 = tf.layers.dense(layer_1, units=512, activation=tf.nn.relu, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='hidden_layer_1')\n",
    "    \n",
    "    layer_3 = tf.layers.dense(layer_2, units=1024, activation=tf.nn.relu, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='hidden_layer_2')\n",
    "    \n",
    "    output_layer = tf.layers.dense(layer_3, units=784, activation=tf.nn.tanh, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='generator_output')\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, initializer, dropout_rate):\n",
    "    \n",
    "    layer_1 = tf.layers.dense(x, units=1024, activation=tf.nn.relu, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='input_layer')\n",
    "    dropout_1 = tf.layers.dropout(inputs=layer_1, rate=dropout_rate, training=True)\n",
    "\n",
    "    \n",
    "    layer_2 = tf.layers.dense(layer_1, units=512, activation=tf.nn.relu, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='disc_layer_1')\n",
    "    dropout_2 = tf.layers.dropout(inputs=layer_2, rate=dropout_rate, training=True)\n",
    "    \n",
    "    \n",
    "    layer_3 = tf.layers.dense(layer_2, units=256, activation=tf.nn.relu, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='disc_layer_2')\n",
    "    dropout_3 = tf.layers.dropout(inputs=layer_3, rate=dropout_rate, training=True)\n",
    "    \n",
    "    \n",
    "    output_layer = tf.layers.dense(layer_3, units=1, activation=tf.sigmoid, kernel_initializer=initializer,\n",
    "                              bias_initializer=initializer, name='disc_output')\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "dropout_rate=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the input data placeholder for the Generator, z, and the Discriminator, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "x = tf.placeholder(tf.float32, shape=(None, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the weight and bias initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Generator and Discriminator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = generator(z, initializer)\n",
    "\n",
    "with tf.variable_scope('discriminator_scope') as scope:\n",
    "    disc_real = discriminator(x, initializer, 0.5)\n",
    "    scope.reuse_variables()\n",
    "    disc_fake = discriminator(G, initializer, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-2\n",
    "disc_loss = tf.reduce_mean(-tf.log(disc_real + epsilon) - tf.log(1 - disc_fake + epsilon))\n",
    "gen_loss = tf.reduce_mean(-tf.log(disc_fake + epsilon))\n",
    "\n",
    "disc_optim = tf.train.AdamOptimizer(lr).minimize(disc_loss)\n",
    "gen_optim = tf.train.AdamOptimizer(lr).minimize(gen_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Run the Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())   \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        ## Define the loss to update as a list\n",
    "        gen_loss = []\n",
    "        disc_loss = []\n",
    "        \n",
    "        ## Run the training iteration\n",
    "        for iter in range(training_data.shape[0] // batch_size):\n",
    "            \n",
    "            ## Batch the input for the discriminator\n",
    "            x_prime = training_data[iter*batch_size:(iter+1)*batch_size]\n",
    "            z_prime = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            ## Run the discriminator session\n",
    "            _, DLoss = sess.run([disc_optim, disc_loss], {x: x_prime, z: z_prime, drop_out: 0.3})\n",
    "            disc_loss.append(DLoss)\n",
    "\n",
    "            ## Run the generator session \n",
    "            z_prime = np.random.normal(0, 1, (batch_size, 100))\n",
    "            _, GLoss = sess.run([gen_optim, gen_loss], {z: z_prime, drop_out: 0.3})\n",
    "            gen_loss.append(GLoss)\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            print('[%d/%d] - loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), epochs, np.mean(D_losses), np.mean(G_losses)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
